{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning notebook\n",
    "\n",
    "This is where we wrote the code that eventually ended up in cleaning.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', parse_dates = True)\n",
    "stores = pd.read_csv('data/store.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna_storetype_a = stores.groupby('StoreType').median().loc['a', 'CompetitionDistance']\n",
    "fillna_storetype_b = stores.groupby('StoreType').median().loc['b', 'CompetitionDistance']\n",
    "fillna_storetype_c = stores.groupby('StoreType').median().loc['c', 'CompetitionDistance']\n",
    "fillna_storetype_d = stores.groupby('StoreType').median().loc['d', 'CompetitionDistance']\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'a')] = fillna_storetype_a\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'b')] = fillna_storetype_b\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'c')] = fillna_storetype_c\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'd')] = fillna_storetype_d\n",
    "\n",
    "train.loc[(train.loc[:, 'Sales'].isnull()) & (train['Open'] == 0), 'Sales'] = 0\n",
    "train.loc[(train.loc[:, 'Sales'].isnull()) & (train['Customers'] == 0), 'Sales'] = 0\n",
    "\n",
    "train.loc[(train.loc[:, 'Customers'].isnull()) & (train['Sales'] == 0), 'Customers'] = 0\n",
    "\n",
    "no_null_sales = train.loc[(train['Sales'].notnull()) | (train['Open'] == 0), :]\n",
    "no_null_sales.loc[:,'Sales'].fillna(0, inplace=True)\n",
    "\n",
    "no_null_sales = no_null_sales.loc[no_null_sales['Store'].notnull(), :]\n",
    "\n",
    "no_null_sales.loc[:,'Date'] = pd.to_datetime(no_null_sales.loc[:,'Date'], format='%Y-%m-%d')\n",
    "no_null_sales.loc[:,'DayOfWeek'] = no_null_sales.loc[:,'Date'].dt.weekday + 1\n",
    "\n",
    "no_null_sales.loc[no_null_sales['StateHoliday'] == 0.0, 'StateHoliday'] = '0'\n",
    "no_null_sales.loc[no_null_sales['StateHoliday'] == 0, 'StateHoliday'] = '0'\n",
    "\n",
    "no_null_sales.loc[(no_null_sales['Open'].isnull()) & (no_null_sales['Sales'] == 0),'Open'] = 0\n",
    "no_null_sales.loc[(no_null_sales['Open'].isnull()) & (no_null_sales['Sales'] > 0),'Open'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slow way to fill in NaNs with the mode\n",
    "# TODO: Figure out fast, vectorized way to do this\n",
    "holiday_nulls = no_null_sales.loc[no_null_sales['StateHoliday'].isnull()]\n",
    "for i, row in holiday_nulls.iterrows():\n",
    "    date = str(row['Date'])\n",
    "    mode = no_null_sales.loc[no_null_sales['Date'] == date, 'StateHoliday'].mode()[0]\n",
    "    no_null_sales.loc[i, 'StateHoliday'] = mode\n",
    "    \n",
    "holiday_nulls = no_null_sales.loc[no_null_sales['SchoolHoliday'].isnull()]\n",
    "for i, row in holiday_nulls.iterrows():\n",
    "    date = str(row['Date'])\n",
    "    mode = no_null_sales.loc[no_null_sales['Date'] == date, 'SchoolHoliday'].mode()[0]\n",
    "    no_null_sales.loc[i, 'SchoolHoliday'] = mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_means = no_null_sales.groupby(['Store', 'DayOfWeek']).mean()['Customers']\n",
    "\n",
    "customer_nulls = no_null_sales.loc[no_null_sales['Customers'].isnull()]\n",
    "for i, row in customer_nulls.iterrows():\n",
    "    store = row['Store']\n",
    "    DayOfWeek = row['DayOfWeek']\n",
    "    mean = customer_means.loc[store, DayOfWeek]\n",
    "    no_null_sales.loc[i, 'Customers'] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_sales.reset_index(inplace = True, drop = True)\n",
    "\n",
    "null_promo = no_null_sales.loc[no_null_sales['Promo'].isnull()]\n",
    "\n",
    "for i, row in null_promo.iterrows():\n",
    "    above_and_below = no_null_sales.loc[i-1, 'Promo'] + no_null_sales.loc[i+1, 'Promo']\n",
    "    if above_and_below == 2:\n",
    "        no_null_sales.loc[i, 'Promo'] = 1\n",
    "    elif above_and_below == 0:\n",
    "        no_null_sales.loc[i, 'Promo'] = 0\n",
    "        \n",
    "null_promo = no_null_sales.loc[no_null_sales['Promo'].isnull()]\n",
    "\n",
    "for i, row in null_promo.iterrows():\n",
    "    date = str(row['Date'])\n",
    "    mean = no_null_sales.groupby('Date').mean().loc[date, 'Promo']\n",
    "    if mean > 0.9:\n",
    "        no_null_sales.loc[i, 'Promo'] = 1\n",
    "    else:\n",
    "        no_null_sales.loc[i, 'Promo'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_sales.to_csv('clean_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = stores.loc[:,['Store', 'StoreType', 'Assortment', 'CompetitionDistance']]\n",
    "stores.to_csv('stores_light.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
