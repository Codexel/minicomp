{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(preds, actuals):\n",
    "    preds = preds.reshape(-1)\n",
    "    actuals = actuals.reshape(-1)\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])\n",
    "\n",
    "def test_da_shit(actuals, preds):\n",
    "    new_test= pd.DataFrame({'Actuals': actuals,'Preds': preds})\n",
    "    new_test = new_test.loc[new_test['Actuals'] != 0,:]\n",
    "    return metric(np.array(new_test['Actuals']), np.array(new_test['Preds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/minicomp/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', parse_dates = True)\n",
    "stores = pd.read_csv('data/store.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/minicomp/lib/python3.8/site-packages/pandas/core/series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "fillna_storetype_a = stores.groupby('StoreType').median().loc['a', 'CompetitionDistance']\n",
    "fillna_storetype_b = stores.groupby('StoreType').median().loc['b', 'CompetitionDistance']\n",
    "fillna_storetype_c = stores.groupby('StoreType').median().loc['c', 'CompetitionDistance']\n",
    "fillna_storetype_d = stores.groupby('StoreType').median().loc['d', 'CompetitionDistance']\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'a')] = fillna_storetype_a\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'b')] = fillna_storetype_b\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'c')] = fillna_storetype_c\n",
    "stores.loc[(stores['CompetitionDistance'].isnull()) & (stores.loc[:,'StoreType'] == 'd')] = fillna_storetype_d\n",
    "\n",
    "train.loc[(train.loc[:, 'Sales'].isnull()) & (train['Open'] == 0), 'Sales'] = 0\n",
    "train.loc[(train.loc[:, 'Sales'].isnull()) & (train['Customers'] == 0), 'Sales'] = 0\n",
    "\n",
    "train.loc[(train.loc[:, 'Customers'].isnull()) & (train['Sales'] == 0), 'Customers'] = 0\n",
    "\n",
    "no_null_sales = train.loc[(train['Sales'].notnull()) | (train['Open'] == 0), :]\n",
    "no_null_sales.loc[:,'Sales'].fillna(0, inplace=True)\n",
    "\n",
    "no_null_sales = no_null_sales.loc[no_null_sales['Store'].notnull(), :]\n",
    "\n",
    "no_null_sales.loc[:,'Date'] = pd.to_datetime(no_null_sales.loc[:,'Date'], format='%Y-%m-%d')\n",
    "no_null_sales.loc[:,'DayOfWeek'] = no_null_sales.loc[:,'Date'].dt.weekday + 1\n",
    "\n",
    "no_null_sales.loc[no_null_sales['StateHoliday'] == 0.0, 'StateHoliday'] = '0'\n",
    "no_null_sales.loc[no_null_sales['StateHoliday'] == 0, 'StateHoliday'] = '0'\n",
    "\n",
    "no_null_sales.loc[(no_null_sales['Open'].isnull()) & (no_null_sales['Sales'] == 0),'Open'] = 0\n",
    "no_null_sales.loc[(no_null_sales['Open'].isnull()) & (no_null_sales['Sales'] > 0),'Open'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.58064127185794"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = no_null_sales[['Store']]\n",
    "y = no_null_sales['Sales']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "lazy_est = pd.concat([X_train, y_train], axis=1)\n",
    "lazy_est = lazy_est.groupby(['Store']).mean()\n",
    "preds = X_test.merge(lazy_est, how = 'left', on = 'Store').loc[:, 'Sales']\n",
    "actuals = np.array(y_test)\n",
    "test_da_shit(actuals, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.42650037519698"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = no_null_sales[['Store', 'DayOfWeek']]\n",
    "y = no_null_sales['Sales']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "lazy_est = pd.concat([X_train, y_train], axis=1)\n",
    "lazy_est = lazy_est.groupby(['Store', 'DayOfWeek']).mean()\n",
    "preds = X_test.merge(lazy_est, how = 'left', on = ['Store', 'DayOfWeek']).loc[:, 'Sales']\n",
    "actuals = np.array(y_test)\n",
    "test_da_shit(actuals, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.438336545019375"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = no_null_sales[['Store', 'DayOfWeek', 'Open']]\n",
    "y = no_null_sales['Sales']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "lazy_est = pd.concat([X_train, y_train], axis=1)\n",
    "lazy_est = lazy_est.groupby(['Store', 'DayOfWeek', 'Open']).mean()\n",
    "preds = X_test.merge(lazy_est, how = 'left', on = ['Store', 'DayOfWeek', 'Open']).loc[:, 'Sales']\n",
    "actuals = np.array(y_test)\n",
    "test_da_shit(actuals, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WILL TAKE 30 MINS TO RUN!!!!!!\n",
    "#Slow and ugly way to fill in NaNs with the mode\n",
    "holiday_nulls = no_null_sales.loc[no_null_sales['StateHoliday'].isnull()]\n",
    "for i, row in holiday_nulls.iterrows():\n",
    "    date = str(row['Date'])\n",
    "    mode = no_null_sales.loc[no_null_sales['Date'] == date, 'StateHoliday'].mode()[0]\n",
    "    no_null_sales.loc[i, 'StateHoliday'] = mode\n",
    "    \n",
    "holiday_nulls = no_null_sales.loc[no_null_sales['SchoolHoliday'].isnull()]\n",
    "for i, row in holiday_nulls.iterrows():\n",
    "    date = str(row['Date'])\n",
    "    mode = no_null_sales.loc[no_null_sales['Date'] == date, 'SchoolHoliday'].mode()[0]\n",
    "    no_null_sales.loc[i, 'SchoolHoliday'] = mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_means = no_null_sales.groupby(['Store', 'DayOfWeek']).mean()['Customers']\n",
    "\n",
    "customer_nulls = no_null_sales.loc[no_null_sales['Customers'].isnull()]\n",
    "for i, row in customer_nulls.iterrows():\n",
    "    store = row['Store']\n",
    "    DayOfWeek = row['DayOfWeek']\n",
    "    mean = customer_means.loc[store, DayOfWeek]\n",
    "    no_null_sales.loc[i, 'Customers'] = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_sales.reset_index(inplace = True)\n",
    "\n",
    "null_promo = no_null_sales.loc[no_null_sales['Promo'].isnull()]\n",
    "\n",
    "for i, row in null_promo.iterrows():\n",
    "    above_and_below = no_null_sales.loc[i-1, 'Promo'] + no_null_sales.loc[i+1, 'Promo']\n",
    "    if above_and_below == 2:\n",
    "        no_null_sales.loc[i, 'Promo'] = 1\n",
    "    elif above_and_below == 0:\n",
    "        no_null_sales.loc[i, 'Promo'] = 0\n",
    "        \n",
    "null_promo = no_null_sales.loc[no_null_sales['Promo'].isnull()]\n",
    "\n",
    "for i, row in null_promo.iterrows():\n",
    "    date = str(row['Date'])\n",
    "    mean = no_null_sales.groupby('Date').mean().loc[date, 'Promo']\n",
    "    if mean > 0.9:\n",
    "        no_null_sales.loc[i, 'Promo'] = 1\n",
    "    else:\n",
    "        no_null_sales.loc[i, 'Promo'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest 1st attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.334534802625598"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_set = no_null_sales.drop(['Date', 'Customers', 'SchoolHoliday', 'Promo'], axis = 1)\n",
    "rf_set.loc[:,'StateHoliday'] = rf_set.loc[:,'StateHoliday'].apply(lambda x: 0 if x=='0' else 1)\n",
    "X = rf_set.drop('Sales', axis = 1)\n",
    "y = rf_set['Sales']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "actuals = np.array(y_test)\n",
    "test_da_shit(actuals, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                 0\n",
       "Store                0\n",
       "DayOfWeek            0\n",
       "Sales                0\n",
       "Customers            0\n",
       "Open                 0\n",
       "Promo            18266\n",
       "StateHoliday         0\n",
       "SchoolHoliday        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_null_sales.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_sales.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_sales.to_csv('Super_clean_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
